{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3-3VmiUfRNU"
      },
      "source": [
        "# HW3 - Q6: Exploring Inductive Bias of Convolutional Neural Networks and Systematic Experimentation in Machine Learning\n",
        "\n",
        "In this homework, we will study 1) what is inductive bias and how it affects the learning process, and 2) how to conduct systematic experiments in machine learning. We will compare convolutional neural networks (CNNs) and multi-layer perceptrons (MLPs) extensively as an example to study these two topics.\n",
        "\n",
        "## 1. Inductive Bias\n",
        "\n",
        "What is inductive bias? It is the assumption that the learning algorithm makes about the problem domain. Suppose that we build a machine learning system. We want to leverage the specific knowledge about the problem domain to make the learning process **more efficient** and the system **generalize much better** with fewer parameters. Let's be more precise. What do exactly **more efficient** and **generalize much better** mean? The learning process is more efficient 1) if we can learn the model with fewer parameters, 2) if we can learn the model with fewer data, and 3) if we can learn the model with fewer iterations. And the system generalizes much better if the model can generalize to the unseen data well.\n",
        "\n",
        "We have already observed the power of inductive bias. We know that CNN generalizes better than MLP even with the same number of parameters. We partially concluded that is because CNN has the inductive bias that the model is translation invariant. We will study the inductive bias of CNN in more detail in this homework.\n",
        "\n",
        "In this homework, we will use the edge detection task as an example to study the inductive bias of CNN. We will compare CNN and MLP extensively. And we will see when CNN can fail.\n",
        "\n",
        "## 2. Systematic Experimentation in Machine Learning\n",
        "\n",
        "How can we prove our hypothesis that CNN has the inductive bias that the model is translation invariant? We conduct extensive experiments in machine learning research (and other fields) to prove our hypothesis. In this context, systematic experimentation refers to running a series of experiments to prove our hypothesis. In this homework, we will study how to conduct systematic experimentation in machine learning.\n",
        "\n",
        "Let's take a step back and think about 1) what our hypothesis is and 2) what experiments are needed to conduct to prove our hypothesis. The first question is easy. The hypothesis is that CNN has the inductive biases of locality and translational invariance. It is not enough to show that CNN performs better than MLP with the same number of parameters. Then, how do we design the experiments to prove our hypothesis? In this homework, we will design the experiments, conduct the experiments, analyze the results, and draw a conclusion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kARHLLg8fRNX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from src.dataset import EdgeDetectionDataset\n",
        "from src.models import *\n",
        "from src.utils import *\n",
        "from src.visualization import *\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjhkOx9jI-z"
      },
      "source": [
        "### Helper functions\n",
        "\n",
        "The following code cell defines function and classes that will be used in the succeeding codes. Feel free to check it if you are not sure about details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3nybaBIfuel"
      },
      "outputs": [],
      "source": [
        "# Moved to src/dataset.py, src/models.py, src/utils.py, src/visualization.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK_EKFhwgUBT"
      },
      "outputs": [],
      "source": [
        "seed = 10\n",
        "set_seed(seed)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
	"# comment out the lines below if using Python version >= 3.12 (but you will need to manually rerun cells)\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAqnKAQofRNZ"
      },
      "source": [
        "## Generate Dataset\n",
        "\n",
        "What would be an excellent dataset to study the inductive bias of CNN? First, have to start with the problem as simple as possible. The complex problem makes it hard to understand the underlying mechanism and is challenging to debug in experimental settings. Hence, we choose the edge detection task as an example to study the inductive bias of CNN. Because\n",
        "1. Edge detection is a straightforward task,\n",
        "2. It is easy to generate the dataset,\n",
        "\n",
        "3. The edge of the image is a very fundamental low-level feature useful to every computer vision task such as object detection and finally,\n",
        "\n",
        "4. Edge detection is an excellent example of studying the inductive bias of CNN.\n",
        "\n",
        "We will generate the dataset for this toy problem. The dataset consists of 10 images of size 28x28 per class, which are all grey scales. Each image contains a vertical edge, a horizontal edge, or nothing. The labels are 0 for vertical edges, 1 for horizontal edges, and 2 for nothing.\n",
        "\n",
        "`EdgeDetectionDataset` class is a dataset class that generates and loads the dataset. The dataset inherits `torch.utils.data.Dataset`, and it generates data when it is initialized. This class takes two arguments: `domain_config` and `transform.` `domain_config` is a dictionary that specifies the domain information of train/valid dataset, such as the number of images per class and the size of the image. `transform` is a function that transforms the image. In this homework, we will use `torchvision.transforms.ToTensor()` to convert the image to a tensor.\n",
        "\n",
        "We highly recommend you read the implementation of `EdgeDetectionDataset` class in `dataset/edge_detection_dataset.py` to understand how the dataset is generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTVTebk0fRNZ"
      },
      "outputs": [],
      "source": [
        "# Define the domain configuration of the dataset\n",
        "set_seed(seed)\n",
        "\n",
        "visualize_data_config = dict(\n",
        "    data_per_class=10,\n",
        "    num_classes=3,\n",
        "    class_type=[\"horizontal\", \"vertical\", \"none\"],\n",
        ")\n",
        "\n",
        "visualize_dataset = EdgeDetectionDataset(visualize_data_config, mode='train', transform=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUrS-FAdfRNZ"
      },
      "source": [
        "## Visualize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnW_atsqfRNa"
      },
      "outputs": [],
      "source": [
        "vis_dataset(visualize_dataset, num_classes=3, num_show_per_class=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzFdaJUXfRNa"
      },
      "source": [
        "## Q1. Overfitting Models to Small Dataset\n",
        "\n",
        "In this problem, we will make our models overfit the small dataset to test the model architecture and our synthetic dataset. We use the same dataset for both models. Let's generate a small dataset with ten images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnzVT0_4fRNb"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "small_dataset_config = None\n",
        "small_dataset = None\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "\n",
        "#############################################################################\n",
        "# TODO: Generate dataset with 10 images per class                          #\n",
        "# Hint: Refer visualize_data_config and use EdgeDetectionDataset and        #\n",
        "# transforms function provided above.                                       #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-T6tY_2fRNb"
      },
      "source": [
        "In this notebook, we will use pytorch dataloader to load the dataset. We will use `torch.utils.data.DataLoader` to load the dataset. `DataLoader` takes two arguments: `dataset` and `batch_size`. `dataset` is the dataset that we want to load. Note that `batch_size` is one of important hyperparameters. We will use `batch_size=32` for this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzm6JSI1S8cC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK8us1MAfRNb"
      },
      "outputs": [],
      "source": [
        "small_dataset_loader = None\n",
        "\n",
        "#############################################################################\n",
        "# TODO: Implement dataloader                                                #\n",
        "# Hint: You should flag shuffle = True for training data loader             #\n",
        "# This flag makes huge difference in training                               #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99NdgqqbfRNb"
      },
      "source": [
        "### Model Architecture\n",
        "\n",
        "MLP has two hidden layer with 10 hidden units and 10 hidden units. The input size is 28x28=784 and the output size is 3. We use ReLU as the activation function. We use cross entropy loss as the loss function.\n",
        "\n",
        "MLP architecture: FC(784, 10) -> ReLU -> FC(10, 10) -> ReLU -> FC(10, 3)\n",
        "\n",
        "CNN has two convolutional layers followed by global average pooling and one fully connected layer. Both convolutional layers have 3 filters whose kernel size is 7. We use ReLU as the activation function. We use cross entropy loss as the loss function.\n",
        "\n",
        "CNN arhitecture is as follows: CONV - RELU - MAXPOOL - CONV - RELU - MAXPOOL - FC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msySKOb_fRNb"
      },
      "source": [
        "### Fitting on Small Dataset\n",
        "\n",
        "Now let's train the model on the small dataset. The final tranining loss should be around 100% for both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0ruzHnCfRNc"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "lr = 1e-2\n",
        "num_epochs = 500\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "cnn_model = SimpleCNN(kernel_size=7)\n",
        "cnn_model.to(device)\n",
        "untrained_cnn_model = deepcopy(cnn_model)\n",
        "\n",
        "mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "mlp_model.to(device)\n",
        "\n",
        "mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"CNN Model has {} parameters\".format(count_parameters(cnn_model, only_trainable=True)))\n",
        "print(\"MLP Model has {} parameters\".format(count_parameters(mlp_model, only_trainable=True)))\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    train_one_epoch(cnn_model, cnn_optimizer, criterion, small_dataset_loader, device, epoch, verbose=False)\n",
        "    train_one_epoch(mlp_model, mlp_optimizer, criterion, small_dataset_loader, device, epoch, verbose=False)\n",
        "\n",
        "_, cnn_acc, _ = evaluate(cnn_model, criterion, small_dataset_loader, device, verbose=False)\n",
        "_, mlp_acc, _ = evaluate(mlp_model, criterion, small_dataset_loader, device, verbose=False)\n",
        "\n",
        "print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_acc, mlp_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHUkBSw6fRNc"
      },
      "source": [
        "We checked that both models can overfit the small dataset. This is one of the most important sanity check. If the model cannot overfit the small dataset, the model is not powerful enough to learn the dataset. In this case, we need to increase the size of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71sdjo6CfRNc"
      },
      "source": [
        "### Visualize Learned Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASl3VJ2zfRNc"
      },
      "outputs": [],
      "source": [
        "cnn_kernel = cnn_model.conv1.weight.data.clone().cpu()\n",
        "untrained_kernel = untrained_cnn_model.conv1.weight.data.clone().cpu()\n",
        "\n",
        "vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained CNN Kernel')\n",
        "vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained CNN Kernel')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-hADVAffRNc"
      },
      "source": [
        "### Question\n",
        "\n",
        "**Can you find any interesting patterns in the learned filters?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KecY3INSfRNc"
      },
      "source": [
        "## Q2. Sweeping the Number of Training Images\n",
        "\n",
        "We understood the given task and checked that both models had enough expressive power. We will compare the performance of MLP and CNN by changing the number of data per class. We expect that the model with proper inductive biases on this task will fit with **fewer training examples**. And let's see which one has inductive biases. In this problem, we will use the same dataset for both models. We sweep the number of training images from 10 to 500. The validation set will be the same for all the experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5AldjOAfRNc"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader_dict = dict()\n",
        "num_images_list = [10, 30, 50, 100]\n",
        "valid_loader = None\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "train_batch_size = 10\n",
        "valid_batch_size = 256\n",
        "#############################################################################\n",
        "# TODO: Implement train_loader_dict for each number of training images.     #\n",
        "# Key: The number of training images (5, 10, 30, 50, and 100)               #\n",
        "# Value: The corresponding dataloader                                       #\n",
        "# The validation set size is 50 images per class                            #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b3wTmmjfRNc"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 30\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_acc_list = list()\n",
        "mlp_acc_list = list()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        train_one_epoch(cnn_model, cnn_optimizer, criterion, train_loader, device, epoch, verbose=False)\n",
        "        train_one_epoch(mlp_model, mlp_optimizer, criterion, train_loader, device, epoch, verbose=False)\n",
        "\n",
        "    cnn_kernel_dict[num_image] = deepcopy(cnn_model.conv1.weight.cpu().detach())\n",
        "    untrained_cnn_kernel_dict[num_image] = deepcopy(untrained_cnn_model.conv1.weight.cpu().detach())\n",
        "\n",
        "    _, cnn_valid_acc, _ = evaluate(cnn_model, criterion, valid_loader, device, verbose=False)\n",
        "    _, mlp_valid_acc, _ = evaluate(mlp_model, criterion, valid_loader, device, verbose=False)\n",
        "\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_valid_acc, mlp_valid_acc))\n",
        "    cnn_acc_list.append(cnn_valid_acc)\n",
        "    mlp_acc_list.append(mlp_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h6JiSJ8fRNd"
      },
      "outputs": [],
      "source": [
        "## Plot the validation accuracy\n",
        "plt.clf()\n",
        "fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=200)\n",
        "ax.plot(num_images_list, cnn_acc_list, marker='o', label='CNN')\n",
        "ax.plot(num_images_list, mlp_acc_list, marker='o', label='MLP')\n",
        "ax.set_xlabel('# of Training Images per Class')\n",
        "ax.set_ylabel('Validation Accuracy (%)')\n",
        "ax.legend()\n",
        "ax.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMC2EUiKfRNd"
      },
      "source": [
        "OK, in most cases, CNN looks like it is performing better than MLP. So can we conclude that CNN has the inductive biases of locality and translational invariance? Not yet. We need to conduct a series of other experiments to show that CNN has such inductive biases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5FYT3VJfRNd"
      },
      "source": [
        "Seemingly, the experiment result is odd. First, the performance of the low data regime ```num_train_images_per_class=10``` is very bad, considering the task is straightforward. Second, we observe that the performance of MLP is better than CNN at some point. At least, CNN should be much better even in a small data regime if it is translational equivariant. How do we debug the model? We will study how to debug the model in the following problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpq_lUkxfRNd"
      },
      "source": [
        "Here are some checklists that you can do to debug the problem.\n",
        "\n",
        "1. Did you check the dataset? For example, is the dataset balanced? Is the dataset noisy? Is the dataset too small?\n",
        "2. Did you check the model architecture? For example, is the model architecture powerful enough to learn the dataset? Is the model architecture too complex? Is the model architecture too simple?\n",
        "3. Did you check the model initialization? For example, is the model initialized properly? Is the model initialized randomly? Is the model initialized with the pre-trained weights?\n",
        "4. Did you check that the model is trained correctly? For example, does the kernel look like an edge detector? What would be the performance of CNN if kernels were initialized with edge detectors?\n",
        "5. Did you check the training procedure? For example, is the training procedure correct? Is the training procedure stable? Is the training procedure too slow?\n",
        "6. Did you optimize the hyperparameters? For example, learning rate, batch size, and the number of epochs.\n",
        "\n",
        "Note that we already checked the dataset, initialization, and model architecture. But we didn't check the step after 3. Let's step 4 first. We will first see what the learned weights look like, initialize the kernels with edge detectors, and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mozw0pMvfRNd"
      },
      "outputs": [],
      "source": [
        "for num_image, cnn_kernel in cnn_kernel_dict.items():\n",
        "    untrained_kernel = untrained_cnn_kernel_dict[num_image]\n",
        "    vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained Kernel - data: {}'.format(num_image))\n",
        "    vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained Kernel - data: {}'.format(num_image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI65xMKGfRNd"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**Compare the learned kernels, untrainable kernels, and edge-detector kernels. What do you observe?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3x7J40mfRNe"
      },
      "source": [
        "### Injecting Inductive Bias: Initialize Kernels with Edge Detectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0EwMo0cfRNe"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 30\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "edge_init_cnn_acc_list = list()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    init_conv_kernel_with_edge_detector(cnn_model)\n",
        "    freeze_conv_layer(cnn_model)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    # logging how training and validation accuracy changes\n",
        "    edge_init_cnn_valid_acc_list = []\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        cnn_train_loss, cnn_train_acc = train_one_epoch(cnn_model, cnn_optimizer, criterion, train_loader, device, epoch, verbose=False)\n",
        "\n",
        "    _, cnn_valid_acc, _ = evaluate(cnn_model, criterion, valid_loader, device, verbose=False)\n",
        "    print(\"CNN Acc: {}\".format(cnn_valid_acc))\n",
        "    edge_init_cnn_acc_list.append(cnn_valid_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LdbKDnXfRNe"
      },
      "outputs": [],
      "source": [
        "## Plot the validation accuracy\n",
        "plt.clf()\n",
        "fig, ax = plt.subplots(1, 1, figsize=(3.5, 3.5), dpi=200)\n",
        "plt.plot(num_images_list, cnn_acc_list, marker='o', label='Randomly Initialized')\n",
        "plt.plot(num_images_list, edge_init_cnn_acc_list, marker='o', label='Edge Initialized')\n",
        "ax.set_xlabel('# of Training Images per Class')\n",
        "ax.set_ylabel('Validation Accuracy (%)')\n",
        "ax.legend()\n",
        "ax.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6bWs2bAfRNe"
      },
      "source": [
        "### Question\n",
        "\n",
        "We freeze the convolutional layer and train only final layer (classifier) in this experiment. For a high data regime, the performance of CNN initialized with edge detectors is worse than CNN initialized with random weights. **Why do you think this happens?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_pzbR7xfRNe"
      },
      "source": [
        "## Q3. Checking the Training Procedure\n",
        "\n",
        "Checking the training procedure is very important. We must log at least training loss, training accuracy, validation loss, and validation accuracy. Let's log such training signals and find out what is going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXqR0s7KfRNe"
      },
      "outputs": [],
      "source": [
        "\n",
        "lr = 1e-2\n",
        "num_epochs = 30\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_acc_list = list()\n",
        "mlp_acc_list = list()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    mlp_results = train_model(mlp_model, mlp_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], mlp_results[\"train_loss\"], mlp_results[\"train_acc\"])\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], mlp_results[\"valid_loss\"], mlp_results[\"valid_acc\"])\n",
        "\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_results[\"final_valid_acc\"], mlp_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQvCsj0ZfRNe"
      },
      "source": [
        "What is going on here? Validation loss and validation accuracy are not flat at the end. It means that the model is not converged. We need to train the model more. Let's train the model with the higher number of epochs. Increase the number of epochs until the validation loss and accuracy are flat.\n",
        "\n",
        "#### Question\n",
        "\n",
        "**List every epochs that you trained the model.** Final accuracy of CNN should be at least 95% for 30 images per class. Answer this question in your submission of the written assignment.\n",
        "\n",
        "#### Question\n",
        "\n",
        "**Check the learned kernels. What do you observe?** Answer this question in your submission of the written assignment.\n",
        "\n",
        "#### Question (Optional)\n",
        "\n",
        "You might find that with the high number of epochs, validation loss of MLP is increasing while validation accuracy increasing.  **How can we interpret this?** Answer this question in your submission of the written assignment.\n",
        "\n",
        "(Hint: you may find papers that discuss calibrations related to this question (e.g., [paper](https://arxiv.org/pdf/1706.04599.pdf))\n",
        "\n",
        "#### Question (Optional)\n",
        "\n",
        "Do hyperparameter tuning. **And list the best hyperparameter setting that you found and report the final accuracy of CNN and MLP.** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbt7NCcmfRNe"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "# TODO: Try other num_epochs. Final accuracy of CNN should be at around     #\n",
        "# 95-99% for 30 images per class.                                           #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################\n",
        "lr = 1e-2\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_acc_list = list()\n",
        "mlp_acc_list = list()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    mlp_results = train_model(mlp_model, mlp_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], mlp_results[\"train_loss\"], mlp_results[\"train_acc\"])\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], mlp_results[\"valid_loss\"], mlp_results[\"valid_acc\"])\n",
        "\n",
        "    cnn_kernel_dict[num_image] = deepcopy(cnn_model.conv1.weight.data.detach().cpu())\n",
        "    untrained_cnn_kernel_dict[num_image] = deepcopy(untrained_cnn_model.conv1.weight.data.detach().cpu())\n",
        "\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_results[\"final_valid_acc\"], mlp_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yQGgyJdfRNe"
      },
      "outputs": [],
      "source": [
        "for num_image, cnn_kernel in cnn_kernel_dict.items():\n",
        "    untrained_kernel = untrained_cnn_kernel_dict[num_image]\n",
        "    vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained CNN Kernel {}'.format(num_image))\n",
        "    vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained CNN Kernel {}'.format(num_image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKu3HnBfRNe"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**How much more data is needed for MLP to get a competitive performance with CNN?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFf7FlffRNf"
      },
      "source": [
        "## Q4. Domain Shift between Training and Validation Set\n",
        "\n",
        "In this problem, we will see how the model performance changes when the domain of the training set and that of the validation set are different. We will generate training set images with edges that locate only half of the image and validation set images with edges that locate only the other half of the image. Let's repeat the same experiment as the previous problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGG2xDmSfRNf"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "train_loader_dict = dict()\n",
        "num_train_images_list = [10, 30, 50, 100]\n",
        "possible_edge_location_ratio = 0.5\n",
        "valid_loader = None\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "batch_size = 10\n",
        "\n",
        "for num_image in num_train_images_list:\n",
        "    train_dataset_config = dict(\n",
        "        data_per_class=num_image,\n",
        "        possible_edge_location_ratio=possible_edge_location_ratio,\n",
        "    )\n",
        "    train_dataset = EdgeDetectionDataset(train_dataset_config, 'train', transform=transforms)\n",
        "    train_loader_dict[num_image] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset_config = dict(\n",
        "    data_per_class=50,\n",
        "    possible_edge_location_ratio=possible_edge_location_ratio,\n",
        ")\n",
        "valid_dataset = EdgeDetectionDataset(valid_dataset_config, 'valid', transform=transforms)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caOnxNaJfRNf"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 300\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_acc_list = list()\n",
        "mlp_acc_list = list()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "cnn_confusion_matrix_dict = dict()\n",
        "mlp_confusion_matrix_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    mlp_results = train_model(mlp_model, mlp_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], mlp_results[\"train_loss\"], mlp_results[\"train_acc\"])\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], mlp_results[\"valid_loss\"], mlp_results[\"valid_acc\"])\n",
        "\n",
        "    cnn_kernel_dict[num_image] = deepcopy(cnn_model.conv1.weight.detach().cpu())\n",
        "    untrained_cnn_kernel_dict[num_image] = deepcopy(untrained_cnn_model.conv1.weight.detach().cpu())\n",
        "\n",
        "    cnn_confusion_matrix_dict[num_image] = cnn_results[\"confusion_matrix\"]\n",
        "    mlp_confusion_matrix_dict[num_image] = mlp_results[\"confusion_matrix\"]\n",
        "\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_results[\"final_valid_acc\"], mlp_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x0tC41IfRNf"
      },
      "outputs": [],
      "source": [
        "for num_image, cnn_kernel in cnn_kernel_dict.items():\n",
        "    untrained_kernel = untrained_cnn_kernel_dict[num_image]\n",
        "    vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained CNN Kernel Data={}'.format(num_image))\n",
        "    vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained CNN Kernel Data={}'.format(num_image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpwH_D8cfRNf"
      },
      "source": [
        "In this example, you will see that both CNN and MLP performance are worse than those in the previous question. If two models learn how to extract edges, they should be able to classify the images with edges even though the edges locate in the other half of the images. However, both models suffer from performance degration (especially for MLP). What would be the problem? To investigate this, let's first look at the confusion matrices for both models  [link](https://en.wikipedia.org/wiki/Confusion_matrix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvNbN5_jfRNf"
      },
      "outputs": [],
      "source": [
        "## Plot the confusion matrix\n",
        "for num_image, cnn_confusion_matrix in cnn_confusion_matrix_dict.items():\n",
        "    mlp_confusion_matrix = mlp_confusion_matrix_dict[num_image]\n",
        "    vis_confusion_matrix(cnn_confusion_matrix, ['horizontal', 'vertical', 'none'], 'CNN-{}-images'.format(num_image))\n",
        "    vis_confusion_matrix(mlp_confusion_matrix, ['horizontal', 'vertical', 'none'], 'MLP-{}-images'.format(num_image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PwtdNiqfRNf"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**Why do you think the confusion matrix looks like this?** Answer this question in your submission of the written assignment.\n",
        "\n",
        "(Hint: Visualize some of the images in the training and validation set. And we are using kernel_size=7, which is large relative to the image size.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L36l7mWWfRNf"
      },
      "source": [
        "We can do better than this. We didn't explore hyperparameter space yet. Let's search hyperparameters that can generalize well to the validation set. We will change the learning rate, the number of epochs, and kernel size for CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7tle6ihfRNf"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "# TODO: Try other num_epochs, lr, kernel_size. The validation accuracy      #\n",
        "# should achieve around 97-100% for 10 images per class.                    #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_valid_acc_list = list()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "\n",
        "cnn_confusion_matrix_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=kernel_size)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], None, None)\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], None, None)\n",
        "\n",
        "    print(\"CNN Acc: {}\".format(cnn_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfU_iYipfRNg"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**Why do you think MLP fails to learn the task while CNN can learn the task?** Answer this question in your submission of the written assignment.\n",
        "\n",
        "(Hint: Think about the model architecture.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJW-oM8CfRNg"
      },
      "source": [
        "## Q5. When is CNN Worse than MLP?\n",
        "\n",
        "In this problem, we will see that CNN is not always better than MLP in the image domain. Using CNN assumes that the data has locally correlated, whatever data looks. We can manually 'whiten' or remove such local correlation simply by applying random permutation to the images. A random permutation matrix is a matrix that has the same number of rows and columns. Each row and column has the same number of 1s. The rest of the elements are 0s. For example, the following is a random permutation matrix.\n",
        "\n",
        "```\n",
        "[[0, 1, 0, 0],\n",
        " [0, 0, 0, 1],\n",
        " [1, 0, 0, 0],\n",
        " [0, 0, 1, 0]]\n",
        "```\n",
        "\n",
        "This matrix randomly reorders the elements of the vector. For example, if we apply this matrix to the vector `[1, 2, 3, 4]`, we will get `[2, 4, 1, 3]`. If we apply this matrix to the image, we will get the image with the same content, but the pixels are randomly shuffled. One property of the random permutation matrix is that it is invertible. It means that we can recover the original image by simply applying the inverse matrix to the shuffled image. From the information-theoretical perspective, the random permutation matrix preserves the mutual information of the image and the label.\n",
        "\n",
        "We will repeat the same experiment as the previous problem. Visualize the dataset first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpJXVvFSfRNg"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "visual_domain_config = None\n",
        "use_permutation = True\n",
        "\n",
        "permutater = np.arange(28 * 28,  dtype=np.int32)\n",
        "np.random.shuffle(permutater)\n",
        "unpermutater = np.argsort(permutater)\n",
        "\n",
        "visual_dataset = None\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "\n",
        "visual_domain_config = dict(\n",
        "    data_per_class=10,\n",
        "    use_permutation=True,\n",
        "    permutater=permutater,\n",
        "    unpermutater=unpermutater,\n",
        ")\n",
        "visual_dataset = EdgeDetectionDataset(visual_domain_config, mode='train', transform=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZlup1KVfRNg"
      },
      "outputs": [],
      "source": [
        "## Visualize the images\n",
        "unpermutator = visual_dataset.get_unpermutater()\n",
        "print('Dataset Image before permutation')\n",
        "vis_unpermuted_dataset(visual_dataset, num_classes=3, num_show_per_class=10, unpermutator=unpermutator)\n",
        "\n",
        "print('Dataset Image after permutation')\n",
        "vis_dataset(visual_dataset, num_classes=3, num_show_per_class=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRzBU-dmfRNg"
      },
      "source": [
        "Now let's train CNN and MLP on the permuted dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNMCIS9JfRNg"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader_dict = dict()\n",
        "num_train_images_list = [10, 30, 50, 100]\n",
        "use_permutation = True\n",
        "valid_loader = None\n",
        "\n",
        "permutater = np.arange(28 * 28,  dtype=np.int32)\n",
        "np.random.shuffle(permutater)\n",
        "unpermutater = np.argsort(permutater)\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "for num_image in num_train_images_list:\n",
        "    train_dataset_config = dict(\n",
        "        data_per_class=num_image,\n",
        "        use_permutation=True,\n",
        "        permutater=permutater,\n",
        "        unpermutater=unpermutater,\n",
        "    )\n",
        "    train_dataset = EdgeDetectionDataset(train_dataset_config, 'train', transform=transforms)\n",
        "    train_loader_dict[num_image] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset_config = dict(\n",
        "    data_per_class=50,\n",
        "    use_permutation=True,\n",
        "    permutater=permutater,\n",
        "    unpermutater=unpermutater,\n",
        ")\n",
        "valid_dataset = EdgeDetectionDataset(valid_dataset_config, 'valid', transform=transforms)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDtXqFzGfRNg"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 300\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10])\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    mlp_results = train_model(mlp_model, mlp_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], mlp_results[\"train_loss\"], mlp_results[\"train_acc\"])\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], mlp_results[\"valid_loss\"], mlp_results[\"valid_acc\"])\n",
        "\n",
        "    cnn_kernel_dict[num_image] = cnn_model.conv1.weight.detach().cpu()\n",
        "    untrained_cnn_kernel_dict[num_image] = untrained_cnn_model.conv1.weight.detach().cpu()\n",
        "\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_results[\"final_valid_acc\"], mlp_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAyBwfr-fRNg"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**What do you observe? What is the reason that CNN is worse than MLP?** Answer this question in your submission of the written assignment.\n",
        "\n",
        "(Hint: Think about the model architecture.)\n",
        "\n",
        "#### Question\n",
        "\n",
        "**Assuming we are decreasing kernel size of CNN. Does the validation accuracy increase or decrease? Why?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdqsWCBvfRNg"
      },
      "source": [
        "Now let's visualize CNN's learned kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7u0UwgnfRNg"
      },
      "outputs": [],
      "source": [
        "for num_image, cnn_kernel in cnn_kernel_dict.items():\n",
        "    untrained_kernel = untrained_cnn_kernel_dict[num_image]\n",
        "    vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained CNN Kernel Data={}'.format(num_image))\n",
        "    vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained CNN Kernel Data={}'.format(num_image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOMAZ7T2fRNh"
      },
      "source": [
        "\n",
        "#### Question\n",
        "\n",
        "**How do the learned kernels look like? Explain why.** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8LB02NYfRNh"
      },
      "source": [
        "From the above example, we can see that CNN is not always better than MLP. We have to think about the domain (or task) of the dataset and the model architecture to decide which model is better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdQWauLNfRNh"
      },
      "source": [
        "## Q6. Increasing the Number of Classes\n",
        "\n",
        "OK, can we conclude that CNN has the inductive bias that the model is translation invariant? Let's try other experiments. We make the task harder. In this problem, we increase the number of classes to 5. The new classes are 0 for horizontal edges, 1 for vertical edges, 2 for diagonal edges, 3 for vertical and horizontal, and 4 for nothing. Let's generate the dataset with 10 images per class and visualize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nd8_YExfRNh"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "visual_domain_config = None\n",
        "\n",
        "visual_dataset = None\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "visual_domain_config = dict(\n",
        "    data_per_class=10,\n",
        "    class_type=['horizontal', 'vertical', 'diagonal', 'both', 'none'],\n",
        "    num_classes=5,\n",
        ")\n",
        "\n",
        "visual_dataset = EdgeDetectionDataset(visual_domain_config, 'train', transform=transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF5MBTlzfRNh"
      },
      "source": [
        "Let's visualize the dataset first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKB6p2K7fRNh"
      },
      "outputs": [],
      "source": [
        "vis_dataset(visual_dataset, 5, 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aePWqygDfRNh"
      },
      "source": [
        "Now let's make the new dataset. In this problem, we also see how the model performance changes as the number of images per class increases. Let's sweep the number of training images 10, 30, 50, and 100. The validation set will be the same (50) for all the cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7p-64oqfRNh"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_dataset_config = None\n",
        "train_loader_dict = dict()\n",
        "num_train_images_list = [10, 30, 50, 100]\n",
        "valid_loader = None\n",
        "\n",
        "transforms = T.Compose([T.ToTensor()])\n",
        "batch_size = 10\n",
        "class_type = ['horizontal', 'vertical', 'diagonal', 'both', 'none']\n",
        "train_dataset_config = dict(\n",
        "    class_type=class_type,\n",
        "    num_classes=len(class_type),\n",
        ")\n",
        "for num_train_images in num_train_images_list:\n",
        "    train_dataset_config['data_per_class'] = num_train_images\n",
        "    train_dataset = EdgeDetectionDataset(train_dataset_config, 'train', transform=transforms)\n",
        "    train_loader_dict[num_train_images] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "valid_dataset_config = dict(\n",
        "    data_per_class=50,\n",
        "    class_type=['horizontal', 'vertical', 'diagonal', 'both', 'none'],\n",
        "    num_classes=len(class_type),\n",
        ")\n",
        "valid_dataset = EdgeDetectionDataset(valid_dataset_config, 'valid', transform=transforms)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aRt_awnfRNh"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 200\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_kernel_dict = dict()\n",
        "untrained_cnn_kernel_dict = dict()\n",
        "\n",
        "cnn_confusion_matrix_dict = dict()\n",
        "mlp_confusion_matrix_dict = dict()\n",
        "\n",
        "cnn_result_dict = dict()\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "    cnn_model = SimpleCNN(kernel_size=7, num_classes=5)\n",
        "    untrained_cnn_model = deepcopy(cnn_model)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    mlp_model = ThreeLayerMLP(hidden_dims=[50, 10], num_classes=5)\n",
        "    mlp_model.to(device)\n",
        "\n",
        "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=lr, momentum=0.9)\n",
        "    cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    mlp_results = train_model(mlp_model, mlp_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = train_model(cnn_model, cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], mlp_results[\"train_loss\"], mlp_results[\"train_acc\"])\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], mlp_results[\"valid_loss\"], mlp_results[\"valid_acc\"])\n",
        "\n",
        "    cnn_kernel_dict[num_image] = cnn_model.conv1.weight.detach().cpu()\n",
        "    untrained_cnn_kernel_dict[num_image] = untrained_cnn_model.conv1.weight.detach().cpu()\n",
        "\n",
        "    cnn_result_dict[num_image] = cnn_results\n",
        "    print(\"CNN Acc: {}, MLP Acc: {}\".format(cnn_results[\"final_valid_acc\"], mlp_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiVF8SsFfRNh"
      },
      "source": [
        "*We look at two types of pooling operations to downsample the image features:*\n",
        "\n",
        "1) Max pooling: The maximum pixel value of the batch is selected.\n",
        "2) Average pooling: The average value of all the pixels in the batch is selected.\n",
        "\n",
        "Up until this point, we have been using the first type of pooling operation (Max pooling). Let's train the same model but with the average pooling to compare these two types of operations!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q4gkdkXfRNh"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "num_epochs = 200\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnnavg_kernel_dict = dict()\n",
        "\n",
        "for num_image, train_loader in train_loader_dict.items():\n",
        "    print(\"Training with {} images\".format(num_image))\n",
        "    set_seed(seed)\n",
        "\n",
        "    cnnavg_model = SimpleCNN_avgpool(kernel_size=7, num_classes=5)\n",
        "    cnnavg_model.to(device)\n",
        "\n",
        "    cnnavg_optimizer = optim.SGD(cnnavg_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    cnnavg_results = train_model(cnnavg_model, cnnavg_optimizer, num_epochs, train_loader, valid_loader)\n",
        "    cnn_results = cnn_result_dict[num_image] # load the results from the previous cell as we have already trained the maxpool model.\n",
        "\n",
        "    vis_training_curve(cnn_results[\"train_loss\"], cnn_results[\"train_acc\"], cnnavg_results[\"train_loss\"], cnnavg_results[\"train_acc\"], label=\"CNN-avgpool\")\n",
        "    vis_validation_curve(cnn_results[\"valid_loss\"], cnn_results[\"valid_acc\"], cnnavg_results[\"valid_loss\"], cnnavg_results[\"valid_acc\"], label=\"CNN-avgpool\")\n",
        "\n",
        "    cnnavg_kernel_dict[num_image] = cnnavg_model.conv1.weight.detach().cpu()\n",
        "\n",
        "    print(\"CNN-maxpool Acc: {}, CNN-avgpool Acc: {}\".format(cnn_results[\"final_valid_acc\"], cnnavg_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM336hS8fRNh"
      },
      "outputs": [],
      "source": [
        "for num_image, cnn_kernel in cnn_kernel_dict.items():\n",
        "    untrained_kernel = untrained_cnn_kernel_dict[num_image]\n",
        "    cnnavg_kernel = cnnavg_kernel_dict[num_image]\n",
        "    vis_kernel(cnn_kernel, ch=0, allkernels=False, title='Trained CNN Kernel Maxpool Data={}'.format(num_image))\n",
        "    vis_kernel(cnnavg_kernel, ch=0, allkernels=False, title='Trained CNN Kernel Avgpool Data={}'.format(num_image))\n",
        "    vis_kernel(untrained_kernel, ch=0, allkernels=False, title='Untrained CNN Kernel Data={}'.format(num_image))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRK9EJCtfRNi"
      },
      "source": [
        "#### Question\n",
        "\n",
        "**Compare the performance of CNN with max pooling and average pooling. What are the advantages of each pooling method?** Answer this question in your submission of the written assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEe8DamEfRNi"
      },
      "source": [
        "\n",
        "## Q7. Wider/Deeper CNNs\n",
        "\n",
        "Can we further improve the performance by making the architecture deeper and wider? In this question, we focus on the dataset where there are only 30 images per class and try to push the performance of the CNNs further.\n",
        "\n",
        "The patterns that we have to detect are 5 but our kernels per layer (`num_filters` in the network definition above) are only 3. Intuitively, this is quite a suboptimal. Here, we will investigate the affect of increasing width and depth. Let's use the same dataset but we will use ```DeeperCNN``` and ```WiderCNN``` in ```cnn.py```. ```DeeperCNN``` has 2 times more layers than ```SimpleCNN``` and ```WiderCNN``` has 2 times more kernels per layer than ```SimpleCNN```. Let's train the models and visualize the validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyTaEqSCfRNi"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "# TODO: Train DeeperCNN and tuning hyperparameters. Try other num_epochs,   #\n",
        "# lr, kernel_size. Also try a different optimizer (e.g., Adam)              #\n",
        "# The validation accuracy can reach above 98% for 30 images per class.      #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = train_loader_dict[30]\n",
        "set_seed(seed)\n",
        "deeper_cnn_model = DeeperCNN(kernel_size=kernel_size)\n",
        "untrained_deeper_cnn_model = deepcopy(deeper_cnn_model)\n",
        "deeper_cnn_model.to(device)\n",
        "\n",
        "deeper_cnn_optimizer = optim.SGD(deeper_cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "# deeper_cnn_optimizer = optim.Adam(deeper_cnn_model.parameters(), lr=lr)  # try me!\n",
        "\n",
        "deeper_cnn_results = train_model(deeper_cnn_model, deeper_cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "vis_training_curve(deeper_cnn_results[\"train_loss\"], deeper_cnn_results[\"train_acc\"], None, None)\n",
        "vis_validation_curve(deeper_cnn_results[\"valid_loss\"], deeper_cnn_results[\"valid_acc\"], None, None)\n",
        "\n",
        "print(\"CNN Acc: {}\".format(deeper_cnn_results[\"final_valid_acc\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WJD44jZfRNi"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "# TODO: Train DeeperCNN and tuning hyperparameters. Try other num_epochs,   #\n",
        "# lr, kernel_size. Also try a different optimizer (e.g., Adam)              #\n",
        "# The validation accuracy can reach above 98% for 30 images per class.      #\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = train_loader_dict[30]\n",
        "set_seed(seed)\n",
        "wider_cnn_model = WiderCNN(kernel_size=kernel_size)\n",
        "untrained_wider_cnn_model = deepcopy(wider_cnn_model)\n",
        "wider_cnn_model.to(device)\n",
        "\n",
        "wider_cnn_optimizer = optim.SGD(wider_cnn_model.parameters(), lr=lr, momentum=0.9)\n",
        "# wider_cnn_optimizer = optim.Adam(wider_cnn_model.parameters(), lr=lr)  # try me!\n",
        "\n",
        "wider_cnn_results = train_model(wider_cnn_model, wider_cnn_optimizer, num_epochs, train_loader, valid_loader)\n",
        "\n",
        "vis_training_curve(wider_cnn_results[\"train_loss\"], wider_cnn_results[\"train_acc\"], None, None)\n",
        "vis_validation_curve(wider_cnn_results[\"valid_loss\"], wider_cnn_results[\"valid_acc\"], None, None)\n",
        "\n",
        "print(\"CNN Acc: {}\".format(wider_cnn_results[\"final_valid_acc\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "dad0cb719410d80ddfd601aac97c786f16717fe3c155f75a38a62246744ec8e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
